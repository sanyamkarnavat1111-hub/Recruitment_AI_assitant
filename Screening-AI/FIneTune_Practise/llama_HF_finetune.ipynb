{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['HF_HOME'] = \"D:/Recruitment_AI_assitant/Screening-AI/Hugging_Face/\"\n",
    "os.environ['HF_TOKEN'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff066d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"csv\" , data_files=\"Dataset/Cleaned_Dataset/cleaned_resume_screening.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer , AutoModelForCausalLM\n",
    "\n",
    "\n",
    "checkpoint = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token' : '[PAD]'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt = \"\"\"Below is the provided resume information of the candidate and also the job description for which the candidate \n",
    "applied for along with the information that if the candidate is fit or unfit for the given job description (0 denotes unfit , 1 denotes fit)\n",
    "\n",
    "Your job as a human resource candidate resume and job description matcher to evaluate if the candidate is fit or unfit.\n",
    "Also use your own logical reasoning as well to predict and contribute to the decision \n",
    "### Resume Text:\n",
    "{}\n",
    "\n",
    "### Job description:\n",
    "{}\n",
    "\n",
    "### Decision:\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prompt_format_function(examples):\n",
    "\n",
    "    texts = []\n",
    "\n",
    "    for resume_text, jd_text, decision in zip(\n",
    "        examples[\"Resume\"],\n",
    "        examples[\"Job_Description\"],\n",
    "        examples[\"Decision\"]\n",
    "    ):\n",
    "        text = prompt.format(resume_text, jd_text, decision) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(prompt_format_function , batched=True , batch_size=8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments , Trainer\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,  # Adjust batch_size based on your GPU memory\n",
    "    per_device_eval_batch_size=1,   # Adjust batch_size based on your GPU memory\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4fb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tempevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
